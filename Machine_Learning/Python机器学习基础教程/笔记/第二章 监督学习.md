# 第二章 监督学习

当我们想要根据经验预测未来，并且经验是被验证过的实例时，都应该使用监督学习。
这些被验证过的经验实例（输入和输出）可以当作训练集，我们利用它们来构建机器学习模型，从而对未见过的新数据做出准确预测。

## 2.1 分类与回归

监督机器学习问题主要有两种，分别叫作分类（classification）与回归（regression）。

### 2.1.1 分类问题

分类问题的目标是预测类别标签（class label），这些标签来自预定义的可选列表（非此即彼）。

分类问题有时可分为==二分类== （binary classification，在两个类别之间进行区分的一种特殊情况）和==多分类==（multiclass  classification，在两个以上的类别之间进行区分）。

二分类问题可看作是一道回答是或否的问题，如“这封电子邮件是垃圾邮件吗？”。

在二分类问题中，我们通常将其中一个类别称为==正类==（positive class），另一个类别称为==反类==（negative class）。这里的“正”并不代表好的方面或正数，而是代表研究对象。因此在找垃圾邮件时，“正”可能指的是垃圾邮件这一类别，需具体问题具体分析。

鸢尾花的例子则属于多分类问题。另一个多分类的例子是根据网站上的文本预测网站所用的语言。这里的类别就是预定义的语言列表。

### 2.1.2 回归问题

回归任务的目标是==预测一个连续值==，编程术语叫作浮点数（floating-point number），数学术 语叫作实数（real number）。
如：根据教育水平、年龄和居住地来预测一个人的年收入，这就是 回归的一个例子。在预测收入时，预测值是一个金额（amount），可以在给定范围内任意 取值。

### 2.1.3 区分分类问题和回归问题

区分分类任务和回归任务有一个简单方法，就是问一个问题：输出是否具有某种==连续性==。 如果在可能的结果之间具有连续性，那么它就是一个回归问题。

## 2.2 泛化、过拟合与欠拟合

### 2.2.1 泛化

在监督学习中，我们想要在训练数据上构建模型，然后能够对没见过的新数据（这些新数据与训练集具有相同的特性）做出准确预测。如果一个模型能够对没见过的数据做出准确预测，我们就说它能够从训练集==泛化==（generalize）到测试集。

### 2.2.2 过拟合

构建一个对现有信息量来说过于复杂的模型，正如我们的新手数据科学家做的那样，这被称为==过拟合==（overfifitting）。如果你在拟合模型时过分关注训练集的细节，得到了一个在训练集上表现很好、但不能泛化到新数据上的模型，那么就存在过拟合。

### 2.2.3 欠拟合

选择过于简单的模型被称为==欠拟合==（underfifitting）。

我们的模型越复杂，在训练数据上的预测结果就越好。

但是，如果我们的模型过于复杂，过多关注训练集中每个单独的数据点，模型就不能很好地泛化到新数据上。

二者之间存在一个最佳位置，可以得到最好的泛化性能。这就是我们想要的模型。

### 2.2.4 模型复杂度与数据集大小的关系

==模型复杂度==与训练数据集中==输入的变化==密切相关。

在不发生过拟合的前提下，数据集中的数据点变化范围越大，可使用的模型越复杂。

## 2.3 监督学习算法

许多算法都有**分类**和**回归**两种形式

### 2.3.2 KNN算法
    KNN算法是一种基于最近邻的算法，用于分类和回归。

### 2.3.3 线性模型
    线性模型利用输入特征的线性函数（linear function）进行预测。
- 用于回归的线性模型，对于回归问题，线性模型预测的一般公式如下：
    ŷ = w[0] * x[0] + w[1] * x[1] + … + w[p] * x[p] + b

这里 x[0] 到 x[p] 表示单个数据点的特征（本例中特征个数为 p+1），w 和 b 是学习模型的
参数，ŷ 是模型的预测结果。对于单一特征的数据集，公式如下： ŷ = w[0] * x[0] + b

这就是高中数学里的直线方程。这里 w[0] 是斜率，b 是 y 轴偏移。

或者，你也可以将预测的响应值看作输入特征的加权求和，权重由 w 的元素给出（可以取负值）。